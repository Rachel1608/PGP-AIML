{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc8616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A) Clearly write outcome of data analysis\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('blogs.zip', 'r') as zipdata:\n",
    "    data_csv = zipdata.open('blogtext.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9d26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d256ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3c1714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61347593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf6fad0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "gender    object\n",
       "age        int64\n",
       "topic     object\n",
       "sign      object\n",
       "date      object\n",
       "text      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9428a1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of              id gender  age              topic      sign          date  \\\n",
       "0       2059027   male   15            Student       Leo   14,May,2004   \n",
       "1       2059027   male   15            Student       Leo   13,May,2004   \n",
       "2       2059027   male   15            Student       Leo   12,May,2004   \n",
       "3       2059027   male   15            Student       Leo   12,May,2004   \n",
       "4       3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "...         ...    ...  ...                ...       ...           ...   \n",
       "681279  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681280  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681281  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681282  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "681283  1713845   male   23            Student    Taurus  01,July,2004   \n",
       "\n",
       "                                                     text  \n",
       "0                  Info has been found (+/- 100 pages,...  \n",
       "1                  These are the team members:   Drewe...  \n",
       "2                  In het kader van kernfusie op aarde...  \n",
       "3                        testing!!!  testing!!!            \n",
       "4                    Thanks to Yahoo!'s Toolbar I can ...  \n",
       "...                                                   ...  \n",
       "681279         Dear Susan,  I could write some really ...  \n",
       "681280         Dear Susan,  'I have the second yeast i...  \n",
       "681281         Dear Susan,  Your 'boyfriend' is fuckin...  \n",
       "681282         Dear Susan:    Just to clarify, I am as...  \n",
       "681283         Hey everybody...and Susan,  You might a...  \n",
       "\n",
       "[681284 rows x 7 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5db687fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B) Clean the Structured Data\n",
    "#i) Missing value analysis and imputation\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12588ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ii) Eliminate Non-English textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72ad74ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut the data for less execution time\n",
    "df = df.head(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd7533c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7670f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in f:\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in f:\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in f:\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in f:\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in f:\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in f:\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cbeab1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>but that zoo exhibit thing was much...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>my fave song for the day: Aimee Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>urlLink America's Best Zoo Exhibit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>'The less one makes declaritive sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>While his status as a media persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id gender  age              topic      sign            date  \\\n",
       "0     2059027   male   15            Student       Leo     14,May,2004   \n",
       "1     2059027   male   15            Student       Leo     13,May,2004   \n",
       "2     2059027   male   15            Student       Leo     12,May,2004   \n",
       "3     2059027   male   15            Student       Leo     12,May,2004   \n",
       "4     3581210   male   33  InvestmentBanking  Aquarius    11,June,2004   \n",
       "...       ...    ...  ...                ...       ...             ...   \n",
       "2995   589736   male   35         Technology     Aries  05,August,2004   \n",
       "2996   589736   male   35         Technology     Aries  05,August,2004   \n",
       "2997   589736   male   35         Technology     Aries  05,August,2004   \n",
       "2998   589736   male   35         Technology     Aries  05,August,2004   \n",
       "2999   589736   male   35         Technology     Aries  05,August,2004   \n",
       "\n",
       "                                                   text  \n",
       "0                Info has been found (+/- 100 pages,...  \n",
       "1                These are the team members:   Drewe...  \n",
       "2                In het kader van kernfusie op aarde...  \n",
       "3                      testing!!!  testing!!!            \n",
       "4                  Thanks to Yahoo!'s Toolbar I can ...  \n",
       "...                                                 ...  \n",
       "2995             but that zoo exhibit thing was much...  \n",
       "2996             my fave song for the day: Aimee Man...  \n",
       "2997              urlLink America's Best Zoo Exhibit...  \n",
       "2998             'The less one makes declaritive sta...  \n",
       "2999             While his status as a media persona...  \n",
       "\n",
       "[3000 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f7dd88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langdetect in f:\\anaconda3\\lib\\site-packages (1.0.9)\n",
      "Requirement already satisfied: six in f:\\anaconda3\\lib\\site-packages (from langdetect) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da836e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61f17400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b628a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].apply(detect_english)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1345588f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>I had an interesting conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>hey, how is everyone doing?  i want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>but that zoo exhibit thing was much...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>my fave song for the day: Aimee Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>'The less one makes declaritive sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>589736</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Aries</td>\n",
       "      <td>05,August,2004</td>\n",
       "      <td>While his status as a media persona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2817 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id gender  age              topic      sign            date  \\\n",
       "0     2059027   male   15            Student       Leo     14,May,2004   \n",
       "2     2059027   male   15            Student       Leo     12,May,2004   \n",
       "3     2059027   male   15            Student       Leo     12,May,2004   \n",
       "4     3581210   male   33  InvestmentBanking  Aquarius    11,June,2004   \n",
       "5     3581210   male   33  InvestmentBanking  Aquarius    10,June,2004   \n",
       "...       ...    ...  ...                ...       ...             ...   \n",
       "2994   589736   male   35         Technology     Aries  05,August,2004   \n",
       "2995   589736   male   35         Technology     Aries  05,August,2004   \n",
       "2996   589736   male   35         Technology     Aries  05,August,2004   \n",
       "2998   589736   male   35         Technology     Aries  05,August,2004   \n",
       "2999   589736   male   35         Technology     Aries  05,August,2004   \n",
       "\n",
       "                                                   text  \n",
       "0                Info has been found (+/- 100 pages,...  \n",
       "2                In het kader van kernfusie op aarde...  \n",
       "3                      testing!!!  testing!!!            \n",
       "4                  Thanks to Yahoo!'s Toolbar I can ...  \n",
       "5                  I had an interesting conversation...  \n",
       "...                                                 ...  \n",
       "2994             hey, how is everyone doing?  i want...  \n",
       "2995             but that zoo exhibit thing was much...  \n",
       "2996             my fave song for the day: Aimee Man...  \n",
       "2998             'The less one makes declaritive sta...  \n",
       "2999             While his status as a media persona...  \n",
       "\n",
       "[2817 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61a6b641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "#2) Preprocess unstructured data to make it consumable for model training.\n",
    "# A) Eliminate All special Characters and Numbers\n",
    "# Select only alphabets\n",
    "import re\n",
    "df.text = df.text.apply(lambda x: re.sub('[^A-Za-z]+', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcc56404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Lowercase all textual data\n",
    "df.text = df.text.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aff97994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10054]\n",
      "[nltk_data]     An existing connection was forcibly closed by the\n",
      "[nltk_data]     remote host>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C)Remove all Stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f1eb6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "df.text = df.text.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f929c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D)Remove all extra white spaces\n",
    "df.text = df.text.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fad0501b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'interesting conversation dad morning talking koreans put money invariably lot real estate cash cash would include short term investments one year well savings accounts reason real estate makes money lot money seen surveys seoul real estate rising per year long stretches even taking account crisis referred imf crisis although imf bailed korea compare korean corporate bonds fell modestly recovered local stock market represented kospi version dow jones index gone appreciably high points points see urllink link see real estate makes sense back conversation noted real big elite real estate investor billion usd see urllink converter properties dad seemed little flabbergasted heck need million dollars need much retire maybe lot risk take real estate south korean asset example north toots horn louder make move country usd worth cents also denominated imf crisis dropped vis vis usd also make bad investment fall victim scam latest urllink good morning city project toast saw lady tv lost everything comment tears know like go rich person beggar one day one saber rattling north korea weak exchange rate little nest egg could almost wiped government almost zero help unemployed disabled otherwise disenfranchised workers role family important money help family go first thus idea koreans go things investing different one apartment urllink jeonse system supports well see usd apartment rent two systems use korea neither western ones except rare circumstances renter signs year contract deposits half market value usd owner monthly rent paid owner invest korean treasury bills per year monthly rent return end term usd returned renter renter signs year year contract deposits market value property usd plus monthly rent month cases value property increases decreases jeonse need topped partially refunded course using usd save key help foreigners reference better thus buy place turn around rent get like buy another place whatever since mortgages korea kind cash society although home equity lines credit system bit different key course real estate prices keep going'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf39f751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_97244/3706867643.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['labels'] = df.apply(lambda row: [row['gender'], str(row['age']), row['topic'], row['sign']], axis=1)\n"
     ]
    }
   ],
   "source": [
    "#3) Build a base Classification model\n",
    "#A)Create dependent and independent variables\n",
    "df['labels'] = df.apply(lambda row: [row['gender'], str(row['age']), row['topic'], row['sign']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01d9238d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>interesting conversation dad morning talking k...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "5  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "\n",
       "                                                text  \\\n",
       "0  info found pages mb pdf files wait untill team...   \n",
       "2  het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                    testing testing   \n",
       "4  thanks yahoo toolbar capture urls popups means...   \n",
       "5  interesting conversation dad morning talking k...   \n",
       "\n",
       "                                    labels  \n",
       "0                 [male, 15, Student, Leo]  \n",
       "2                 [male, 15, Student, Leo]  \n",
       "3                 [male, 15, Student, Leo]  \n",
       "4  [male, 33, InvestmentBanking, Aquarius]  \n",
       "5  [male, 33, InvestmentBanking, Aquarius]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18e23912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text','topic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ccba310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interesting conversation dad morning talking k...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>hey everyone want go game still looking job st...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>zoo exhibit thing mucho mucho funny</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>fave song day aimee mann pavlov bell album los...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>less one makes declaritive statements less apt...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>status media personality arguably changes rule...</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2817 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text              topic\n",
       "0     info found pages mb pdf files wait untill team...            Student\n",
       "2     het kader van kernfusie op aarde maak je eigen...            Student\n",
       "3                                       testing testing            Student\n",
       "4     thanks yahoo toolbar capture urls popups means...  InvestmentBanking\n",
       "5     interesting conversation dad morning talking k...  InvestmentBanking\n",
       "...                                                 ...                ...\n",
       "2994  hey everyone want go game still looking job st...         Technology\n",
       "2995                zoo exhibit thing mucho mucho funny         Technology\n",
       "2996  fave song day aimee mann pavlov bell album los...         Technology\n",
       "2998  less one makes declaritive statements less apt...         Technology\n",
       "2999  status media personality arguably changes rule...         Technology\n",
       "\n",
       "[2817 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0902d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B) Split data into train and test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.text.values, df.topic.values, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02311ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C) Vectorize data using any one vectorizer.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34a1b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aa anger',\n",
       " 'aa compared',\n",
       " 'aa nice',\n",
       " 'aaa',\n",
       " 'aaa take',\n",
       " 'aaa travel',\n",
       " 'aaaaaah',\n",
       " 'aaaaack',\n",
       " 'aaaah',\n",
       " 'aaaah wisdom',\n",
       " 'aaagh']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2def6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ae99b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts = dict()\n",
    "\n",
    "for topic in df.topic.values:\n",
    "    for topic in topic:\n",
    "        if topic in topic_counts:\n",
    "            topic_counts[topic] += 1\n",
    "        else:\n",
    "            topic_counts[topic] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13101a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': 500,\n",
       " 't': 1281,\n",
       " 'u': 531,\n",
       " 'd': 952,\n",
       " 'e': 2534,\n",
       " 'n': 3749,\n",
       " 'I': 90,\n",
       " 'v': 79,\n",
       " 's': 203,\n",
       " 'm': 100,\n",
       " 'B': 95,\n",
       " 'a': 307,\n",
       " 'k': 522,\n",
       " 'i': 1092,\n",
       " 'g': 1801,\n",
       " 'U': 436,\n",
       " 'N': 45,\n",
       " 'o': 3336,\n",
       " '-': 136,\n",
       " 'P': 45,\n",
       " 'r': 349,\n",
       " 'f': 45,\n",
       " 'E': 235,\n",
       " 'c': 1753,\n",
       " 'C': 14,\n",
       " 'M': 16,\n",
       " 'p': 75,\n",
       " 'R': 75,\n",
       " 'A': 4,\n",
       " 'L': 2,\n",
       " 'b': 2,\n",
       " 'T': 1475,\n",
       " 'h': 1475,\n",
       " 'l': 1475,\n",
       " 'y': 1475}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6f32a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=sorted(topic_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_test = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f1fcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D) Build a base model for Supervised Learning - Classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf = OneVsRestClassifier(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71776573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e32715e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_topic = clf.predict(X_test_bow)\n",
    "predicted_scores = clf.decision_function(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7631ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_inversed = mlb.inverse_transform(predicted_topic)\n",
    "y_test_inversed = mlb.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "795d1e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\tsharp ring course liked ring\n",
      "True topic:\tT,c,e,g,h,l,n,o,y\n",
      "Predicted topic:\tT,c,e,g,h,l,n,o,y\n",
      "\n",
      "\n",
      "Title:\tcrisp cold morning certainly wake much tongues flame\n",
      "True topic:\tT,c,e,g,h,l,n,o,y\n",
      "Predicted topic:\tT,c,e,g,h,l,n,o,y\n",
      "\n",
      "\n",
      "Title:\tcircle irony welcomes two latest members shannon erwin johnathan better late never shipley please see prior notes proper blogging contained prior posts archive section good reference questions episode news apparently several years e e years e e luke leia appear infants e towards end rant getting tired cgi used create human human like creatures landscapes ok cgi creatures still fancy cartoon characters indistinguishable actual creatures take seriously e serve clever distracting talking head might otherwise serious scene making comedy kids film may lucas trying perhaps perspective overly critical admittedly took original trilogy story somewhere modern mythology serious science fiction films something else something modern deep somehow thankfully endure watching cartoon lizard rabbit thing step feces time get weary c po switched heads another robot gag yes funny first scene occurs however ceases funny fifth time reminded look c po switched heads another robot hilarious huh point cringing hoping stop get plot thread watching jedi council beng attacked forces darth tyrannus say warned though even episode one namely ewoks episode six even tolerable given things upswing sort pleasant thing see furry warriors triumph evil empire point feel immense scale overall conflict galactic conflict good evil spanning hundreds worlds coming together final battle ewoks distracting e seem like small part much larger tapestry e e however sight gags bad puns seem given weight rest events story ewoks little something kids e way symbolize hope happier future galaxy important great arc things screen time given balanced bigger events accordingly heck couple ewoks even shown dying battle lucas dared showing gungans getting creamed afraid scaring kids little bolder e assination attempt beginning easy kill characters met oh seconds blew ok seconds count screen time padme stand e see point qui gon dies end e unfortunate obi wan dies end e tragedy probably something acting character development etc e obi wan rest gang never compete cartoon characters background sets screen time like said jls pretty pictures new trilogy different crowd lighter goofier end kid movie accept find enjoy whole experience much less critical cynical eye serious taken posing pictures jedi outfit total strangers\n",
      "True topic:\tT,c,e,g,h,l,n,o,y\n",
      "Predicted topic:\tg,i,k,n,o\n",
      "\n",
      "\n",
      "Title:\tperson always gets good job relentless persistent getting job person goes extra mile unnecessary person goes beyond something different unique playing job search methods years found startling pattern people bend traditional methods traditional methods creating resume cover letter filling job application law states must go beyond methods course recommend striving want guarantee get noticed unique saying anything get employer company attention want think create ways show value provide accomplishments results accomplished track record let give examples rarely used spice resume cover letter including testimonial current past employer give testimonial based skills accomplishments telling strike interest one reads resume cover letter come plan nothing rocks company employer boat like person comes plan increase company association revenue productivity take moment brainstorm ideas could improve value company applying well worth time effort included within top follow yes job seekers usually follow remember companies hardly ever hire person days takes weeks fill position guess employer remember time comes hire one individual person multiple exposures always remember human mind stores much easier repetition afraid follow really crush competition career portfolio yes matter industry part create career portfolio even working long portfolio perceive use leverage others create ultimate career portfolio career continue grow prosper financially years come proof evidence shall set free david green author hiring manager distinguish marketing llc want information receive job days less including free lessons urllink write resume cover letter career portfolio tips click http www forcareersuccess com\n",
      "True topic:\tB,S,c,e,i,n,r,s,u,v\n",
      "Predicted topic:\tB,S,c,e,i,n,r,s,u,v\n",
      "\n",
      "\n",
      "Title:\tcome know want feel know still want always seem want ataris fitting lyric snippit ah mazing need something think need make move towards future dun dun dun going put ex claim ation mark interesting way much im tired tired shouldnt tired vacation boating fun ya also want camp backyard gentlemen hee hee would much fun absolutly\n",
      "True topic:\tS,d,e,n,t,u\n",
      "Predicted topic:\te,n\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Title:\\t{}\\nTrue topic:\\t{}\\nPredicted topic:\\t{}\\n\\n'.format(\n",
    "        X_test[i],\n",
    "        ','.join(y_test_inversed[i]),\n",
    "        ','.join(pred_inversed[i])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7de1d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#E) Clearly print Performance Metrics.\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def print_evaluation_scores(y_val, predicted):\n",
    "    print('Accuracy score: ', accuracy_score(y_val, predicted))\n",
    "    print('F1 score: ', f1_score(y_val, predicted, average='micro'))\n",
    "    print('Average precision score: ', average_precision_score(y_val, predicted, average='micro'))\n",
    "    print('Average recall score: ', recall_score(y_val, predicted, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c40548dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words\n",
      "Accuracy score:  0.5514184397163121\n",
      "F1 score:  0.8177726485862666\n",
      "Average precision score:  0.7151916671295193\n",
      "Average recall score:  0.7961797752808989\n"
     ]
    }
   ],
   "source": [
    "print('Bag-of-words')\n",
    "print_evaluation_scores(y_test, predicted_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2d218ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) Improve Performance of model. \n",
    "#A) Experiment with other vectorisers\n",
    "#preprocessing with two methods\n",
    "#Method1 =Normalization\n",
    "\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "def remove_punctuation(text):\n",
    "    return re.sub('[^a-zA-Z]',' ', str(text))\n",
    "\n",
    "def normalize_document(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = lower_case(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e253a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_97244/567325569.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['normalize_document'] = df['text'].apply(normalize_document)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>normalize_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>Student</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>Student</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>Student</td>\n",
       "      <td>testing testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interesting conversation dad morning talking k...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>interesting conversation dad morning talking k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              topic  \\\n",
       "0  info found pages mb pdf files wait untill team...            Student   \n",
       "2  het kader van kernfusie op aarde maak je eigen...            Student   \n",
       "3                                    testing testing            Student   \n",
       "4  thanks yahoo toolbar capture urls popups means...  InvestmentBanking   \n",
       "5  interesting conversation dad morning talking k...  InvestmentBanking   \n",
       "\n",
       "                                  normalize_document  \n",
       "0  info found pages mb pdf files wait untill team...  \n",
       "2  het kader van kernfusie op aarde maak je eigen...  \n",
       "3                                    testing testing  \n",
       "4  thanks yahoo toolbar capture urls popups means...  \n",
       "5  interesting conversation dad morning talking k...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['normalize_document'] = df['text'].apply(normalize_document)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c4f42e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_97244/275242146.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Method1'] = df['normalize_document'].apply(lambda x : nltk.word_tokenize(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>normalize_document</th>\n",
       "      <th>Method1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>Student</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[info, found, pages, mb, pdf, files, wait, unt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>Student</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[het, kader, van, kernfusie, op, aarde, maak, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>Student</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>[testing, testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[thanks, yahoo, toolbar, capture, urls, popups...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interesting conversation dad morning talking k...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>interesting conversation dad morning talking k...</td>\n",
       "      <td>[interesting, conversation, dad, morning, talk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              topic  \\\n",
       "0  info found pages mb pdf files wait untill team...            Student   \n",
       "2  het kader van kernfusie op aarde maak je eigen...            Student   \n",
       "3                                    testing testing            Student   \n",
       "4  thanks yahoo toolbar capture urls popups means...  InvestmentBanking   \n",
       "5  interesting conversation dad morning talking k...  InvestmentBanking   \n",
       "\n",
       "                                  normalize_document  \\\n",
       "0  info found pages mb pdf files wait untill team...   \n",
       "2  het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                    testing testing   \n",
       "4  thanks yahoo toolbar capture urls popups means...   \n",
       "5  interesting conversation dad morning talking k...   \n",
       "\n",
       "                                             Method1  \n",
       "0  [info, found, pages, mb, pdf, files, wait, unt...  \n",
       "2  [het, kader, van, kernfusie, op, aarde, maak, ...  \n",
       "3                                 [testing, testing]  \n",
       "4  [thanks, yahoo, toolbar, capture, urls, popups...  \n",
       "5  [interesting, conversation, dad, morning, talk...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Method1'] = df['normalize_document'].apply(lambda x : nltk.word_tokenize(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af9db55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>Method1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>Student</td>\n",
       "      <td>[info, found, pages, mb, pdf, files, wait, unt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>Student</td>\n",
       "      <td>[het, kader, van, kernfusie, op, aarde, maak, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>Student</td>\n",
       "      <td>[testing, testing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>[thanks, yahoo, toolbar, capture, urls, popups...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interesting conversation dad morning talking k...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>[interesting, conversation, dad, morning, talk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              topic  \\\n",
       "0  info found pages mb pdf files wait untill team...            Student   \n",
       "2  het kader van kernfusie op aarde maak je eigen...            Student   \n",
       "3                                    testing testing            Student   \n",
       "4  thanks yahoo toolbar capture urls popups means...  InvestmentBanking   \n",
       "5  interesting conversation dad morning talking k...  InvestmentBanking   \n",
       "\n",
       "                                             Method1  \n",
       "0  [info, found, pages, mb, pdf, files, wait, unt...  \n",
       "2  [het, kader, van, kernfusie, op, aarde, maak, ...  \n",
       "3                                 [testing, testing]  \n",
       "4  [thanks, yahoo, toolbar, capture, urls, popups...  \n",
       "5  [interesting, conversation, dad, morning, talk...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['normalize_document'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1585d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "458ed92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d072c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key : ['like', 'one', 'get', 'know', 'think', 'go', 'would', 'time', 'really', 'well', 'good', 'people', 'urllink', 'got', 'nbsp', 'back', 'much', 'see', 'going', 'day']\n",
      "Total_Keys: 25395\n",
      "----------------------------------------\n",
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0. 15. 14. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  1.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  1. ...  1.  0.  0.]\n",
      " [ 0.  1.  0. ...  0.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "text =df['Method1']\n",
    "sentence = []\n",
    "for i in text:\n",
    "    sentence.append(i)\n",
    "\n",
    "# using tokenizer \n",
    "model = Tokenizer()\n",
    "model.fit_on_texts(sentence)\n",
    "\n",
    "#print keys \n",
    "keys = list(model.word_index.keys())\n",
    "print(f'Key : {keys[0:20]}')\n",
    "print('Total_Keys:', len(keys)) \n",
    "print('-'*40)\n",
    "\n",
    "#create bag of words representation \n",
    "bow = model.texts_to_matrix(sentence, mode='count')\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64a7c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectorizer\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word',\n",
    "                        tokenizer=dummy_fun,\n",
    "                        preprocessor=dummy_fun,\n",
    "                        token_pattern=None,\n",
    "                        stop_words = 'english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cedfb1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:404: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2817, 25208)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_method1 = tfidf.fit_transform(df.Method1)\n",
    "tfidf_method1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8421dd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf_df_method1 = pd.DataFrame(tfidf_method1.toarray(),\n",
    "             columns = tfidf.get_feature_names(),\n",
    "             index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c5d466e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urllink    0.024477\n",
       "like       0.023928\n",
       "know       0.017468\n",
       "time       0.015379\n",
       "think      0.015340\n",
       "good       0.015107\n",
       "really     0.014560\n",
       "nbsp       0.014527\n",
       "people     0.014080\n",
       "got        0.013148\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df_method1.mean().sort_values(ascending = False).head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2eff270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C) Tune Parameters/Hyperparameters of the model/s. [\n",
    "def sentence(text):\n",
    "    sent = ' '.join(text)\n",
    "    #for i in txt:\n",
    "     #   sent.append(' '.join(i))\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f0f8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_97244/3459411117.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Method1'] = df['Method1'].apply(sentence)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>Method1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>Student</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>Student</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>Student</td>\n",
       "      <td>testing testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interesting conversation dad morning talking k...</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>interesting conversation dad morning talking k...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              topic  \\\n",
       "0  info found pages mb pdf files wait untill team...            Student   \n",
       "2  het kader van kernfusie op aarde maak je eigen...            Student   \n",
       "3                                    testing testing            Student   \n",
       "4  thanks yahoo toolbar capture urls popups means...  InvestmentBanking   \n",
       "5  interesting conversation dad morning talking k...  InvestmentBanking   \n",
       "\n",
       "                                             Method1  \n",
       "0  info found pages mb pdf files wait untill team...  \n",
       "2  het kader van kernfusie op aarde maak je eigen...  \n",
       "3                                    testing testing  \n",
       "4  thanks yahoo toolbar capture urls popups means...  \n",
       "5  interesting conversation dad morning talking k...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Method1'] = df['Method1'].apply(sentence)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca04ac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training utterances: 2394\n",
      "Validation utterances: 423\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Method1'].values, df['topic'].values, test_size=0.15, random_state=42)\n",
    "print('Training utterances: {}'.format(X_train.shape[0]))\n",
    "print('Validation utterances: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fac76644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "de1de414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<2394x23468 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 154453 stored elements in Compressed Sparse Row format>,\n",
       " <423x23468 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 23193 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27d24c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<2394x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 83369 stored elements in Compressed Sparse Row format>,\n",
       " <423x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 12836 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#B) Build classifier Models using other algorithms than base model\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "ch2 = SelectKBest(chi2, k=5000)\n",
    "X_train = ch2.fit_transform(X_train, y_train)\n",
    "X_test = ch2.transform(X_test)\n",
    "\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca6cfd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5224586288416075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "model_mnb_m1 = MultinomialNB()\n",
    "model_mnb_m1.fit(X_train, y_train)\n",
    "pred = model_mnb_m1.predict(X_test)\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d9234a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_Score: 0.6264775413711584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "print('RF_Score:', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "683dfec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB_Score: 0.6335697399527187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "pred = bnb.predict(X_test)\n",
    "print('NB_Score:', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04b641ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "          Accounting       0.00      0.00      0.00         1\n",
      "             Banking       0.00      0.00      0.00         2\n",
      "    BusinessServices       0.00      0.00      0.00         2\n",
      "Communications-Media       0.00      0.00      0.00         2\n",
      "           Education       0.50      0.20      0.29        25\n",
      "         Engineering       1.00      0.06      0.11        17\n",
      "            Internet       0.00      0.00      0.00         2\n",
      "   InvestmentBanking       0.50      0.10      0.17        10\n",
      "          Non-Profit       0.00      0.00      0.00         9\n",
      "             Science       0.00      0.00      0.00         6\n",
      "   Sports-Recreation       0.80      0.50      0.62         8\n",
      "             Student       0.58      0.43      0.50        58\n",
      "          Technology       0.70      0.94      0.80       214\n",
      "              indUnk       0.42      0.46      0.44        67\n",
      "\n",
      "            accuracy                           0.63       423\n",
      "           macro avg       0.32      0.19      0.21       423\n",
      "        weighted avg       0.60      0.63      0.58       423\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#D) Clearly print Performance Metrics. \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ce327d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) Share insights on relative performance comparison\n",
    "#A) Which vectorizer performed better? Probable reason?. \n",
    "#TF-IDF Vectorizer performed better in Accuracy, but when compared to precision, f1-score and recall Count Vectorizer performed better than TF-IDF Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "927ba8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#B) Which model outperformed? Probable reason?\n",
    "# Out of all the models performed from Count vectorizer, Bernoulli Naive bayes model from TF-IDF vectorizer performed better with 63% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9d42d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C. Which parameter/hyperparameter significantly helped to improve performance?Probable reason?\n",
    "#MultiLabelBinarizer helped to improve performance more accurately, because it predicted accurately same as true topic.\n",
    "#BernoulliNB helped to improve performance compared to RandomForest,MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09cea7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D) According to you, which performance metric should be given most importance, why?. \n",
    "# Count Vectorier can be given most importance, because it evaluation metrics has better performance compared to TF-IDF vectorizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
